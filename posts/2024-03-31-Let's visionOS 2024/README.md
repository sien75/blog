<h1>Let's visionOS 2024</h1>

## 一点感悟

刚参加了[Let's visionOS 2024](https://letsvisionos24.swiftgg.team/cn/)活动, 有一些感悟, 趁还没忘记, 赶紧在这里记录下来.

这场活动是以visionOS为主, 主要是关于visionOS的产品形态, 技术预览, 商业模式, 以及未来的发展等方面的讨论.

## 第一天

第一天早早去了, 会场的外面有18个展位, 基本上以展示在visionOS上的app为主, 其中有不少都可以体验visionPro, 不过是需要排队, 而且很多人都是一直在戴着展位的visionPro, 我也不好等到机会.

在其中的inSpaze展位上, 刚好有机会, 上一个老哥走了, 我就向展位小哥要了visionPro过来体验了一把. visionPro的体验总体来说倒也没有那么惊艳, 一带上去不知道干啥, 后面慢慢适应了, 尝试了一下捏合点击, 捏合后手指拖动, 走到3D物体处实际点击. 不过总是感觉按钮对不准, 我在看那个按钮, 但是按钮不聚焦, 可能是眼球追踪不好适配吧.

对于第一天上午的演讲, 说实话并没有感受到多么有趣, 现在想起来, 可能一开始来, 还没有适应, 还不清楚这场活动究竟是要聊什么, 而且前3位都是非美国人讲英语, 只是听个大概, 听个乐呵. 另外, Jordi(第一位演讲者)很帅.

第一天下午, 依旧是几场英语演讲, 听困了.

来自日本的Satoshi, live code, 现场撸代码, 每当做成一个feature就嘀咕一声"yes"庆祝一下, 哈哈也是很有特点.

Adam, 听起来是来推销Godot引擎的, 并且演示了几款游戏, 个人有一定的意愿尝试Godot引擎, 不过比对起Unity来还是有些功能不足.

开发方案这块多说几句. 经过这场活动, 个人更加偏向于visionOS的原生开发, 对于游戏引擎的选择(Unity vs Godot)就不是那么重要了. 在第二天的技术分会场的Unity主题分享上, 结尾也是说到, 如果你的应用更加侧重于AR而不是VR, 原生开发比Unity更适合. 我觉得visionOS的主要特点是体现在AR(或者说MR)能力上, 并非侧重于大型游戏开发, 如果希望进行visionOS开发, 学习原生的Swift, ARKit, RealityKit就会更好一点, Unity方案更适合已经会Unity的人低成本迁移.

当然, 从个人喜好的角度, 我也是喜欢visionOS原生开发. 一个全新的平台, 什么都是新的, 但是却不复杂, 没有太多的历史概念, 而且, 是Apple出品.

第一天下午的最后一场演讲者, 是真格基金投资合伙人徐梧, 是一场针对于空间计算时代的展望, 侧重于宏观角度和创业视角. 这场演讲~~画饼~~非常精彩, 让我觉得一千块钱的票价, 值了.

这场演讲里, 阐述了一个观点: XR不足以描述下一代计算平台的特点, 应该使用空间计算(Spatial Computation)更准确.

徐梧对于空间计算的未来比较看好, 他认为对于空间计算时代的6个难题:

* 显示
* 交互
* MR
* 操作系统
* 芯片
* 小型化

已经有了显著的进展, 并且往后走的解决方案也相对清晰, 这意味者无论外表怎样, 外界怎么看, 驱动空间计算行业的根本逻辑已经逐渐成熟. 他表示这一次真真切切感受到空间计算时代的到来(PS: 的产品能力真强), 建议个人开发者和创业公司在未来3年内做好充分准备(不然就错过咯). 在开发App时, 他建议, 对于目前阶段, 应该多开发小型App, 多尝试, 并重点针对新设备的优点设计产品.

之后, 他又阐述了空间计算时代应用创业的5个方向:

* 平面应用的升级 - 现有功能的迁移, 当然交互形式上会发生一定的变更, 但是这些功能还都是需要的
* 媒体内容的升级 - 长视频时代有Youtube, 短视频时代的Tiktok, 那么在空间计算时代, 视频(或者其他的形式)制作会跟之前完全不一样, 这是一个新的赛道
* 实体的数字化 - 比如说, 是不是并不需要实体的显示器, 戴上头显, 内容可以显示在任何地方, 是不是这种展示方式更合适呢?
* 完全沉浸体验 - 其实说的就是VR功能, 但是在新时代下也会面临重新洗牌

这5个方向, 总结起来, 本质上就是: 空间计算的本质就是空间的数字化.

## 第二天

新加坡老哥, 演示空间音频App.

查理老哥, 比对了visionos和初期的ios ipados watchos用户量，目前的用户量较少，但是后续越来越多，现在是make money的机会，而且目前的visionos用户付费意愿非常高，后面又介绍了4种商业模式，广告、购买、内购、订阅.

查理老哥，来自美国，英语非常标准，而且是做播客的，表达很清楚，ppt做的挺好.

长得也很有特点哈哈哈.

最后, 是Jane对于一个AI+XR的备忘录应用展示, 她提到了一些观点:

* prompt编写非常重要，多一点可能没关系，因为大模型读比写快很多，在prompt里规定好格式，使输出简洁，这样可能一方面更快，另一方面可能花费更低，因为计费上有些模型计输出token量比计输入token量更贵
* 端侧部署处理专门领域的大模型，在算力有限时更高效
* ai处理所有的数字场景都不可靠，可以通过给示例或者调用函数解决，大模型可以和固定编码的函数相结合

## visionOS上的场景类型思考

A **Shared Space**下, 基于现实, 是立体空间, 物体和窗口可以响应位置和视线角度的变化, 但是好像和现实并没有交互.

B **Full Space下的mixed场景**, 基于现实, 是立体空间, 物体和窗口可以响应位置和视线角度的变化, 并且可以和现实进行交互.

C **Full Space下的full(immersive)场景**, 是虚拟virtual的, 但是没法立体(全景照片 or 空间视频), 因为用户并不在实际的场景里, 根本没法和场景里的东西交互, 也就不能响应位置变化. 响应视线角度的变化是可以做到的, 就是旋转一下嘛, 不过也不是一定要响应视角变化, 纯fixed体验也是可以的.

玩游戏的体验:

* 首先是沉浸式体验, 这个用到C场景. 没人想在玩游戏的时候摇头晃脑, 所以事实上视角变化体验沉浸感只能是轻体验, vR游戏其实只能是把头显作为一块360°大屏幕. 不过vsp到是支持用户的手部等轻微的动作(比如说挥砍, 魔法动作等), 到时候就不是按手柄或者键盘了, 可以实际挥动拳头打怪了😂
* 现实中的大屏体验, 这个用到B场景. 也就是说并不想完全沉浸, 或者游戏没必要做成完全沉浸, 这其实可以模拟出一块大屏幕来, 和其他的屏幕场景没啥太大区别
* fixed大屏体验, 这个用到C场景. 这个其实是传统VR场景, 就是说其实玩游戏的时候, 是不是没必要响应视角变化呢? 这时我觉得不管屏幕是大屏还是360°屏, 都需要把现实屏蔽掉, 不然应该是会晕的

和现实的游戏房结合:

不过再一想, 事实上可以设置一定的场地大小和道具, 虽然在真实世界里平平无奇, 但是visionOS可以将场景变得风格化, 像游戏, 所以其实未来VR也可以响应位置的变化, 并增加触感.

交互方式:

手势 / 语音 / 真实设备(手柄 控制器 键盘 道具等) / 虚拟设备(事实上是手势+真实设备虚拟化) / 其他动作(比如摇头) / 环境光线变化

## AI + 空间计算的时代

从之前的hackthon活动起, 我一直坚持未来是AI+强交互的想法. 脑机接口, 触觉味觉这些还很遥远, 暂时实现不了, 但是现在visionPro出来了, 强化了视觉展示, 那么强交互在现在就是指空间计算.

AI + 空间计算 = 下一个时代.

平面+专业操作+专业语言 ----> 空间+自然操作+通用对话.
